"""
KR Market AI Stock Analysis System - Flask Backend
Based on BLUEPRINT_02_BACKEND_FLASK_CORE.md

Full-featured Flask app with:
- Background price scheduler (5-min updates)
- 19 KR Market API endpoints
- Sector mapping system
- Caching patterns
- Error handlers
"""

import os
import json
import threading
import pandas as pd
import numpy as np
import yfinance as yf
import time
import traceback
from flask import Flask, render_template, jsonify, request
from datetime import datetime
from dotenv import load_dotenv

# Load environment variables explicitly
load_dotenv()

app = Flask(__name__)

# Enable CORS for frontend access
from flask_cors import CORS
CORS(app, resources={r"/api/*": {"origins": "*"}})

# ==================== BACKGROUND PRICE SCHEDULER ====================

# [NEW] ì‹¤ì‹œê°„ ë°ì´í„° - FinanceDataReader (optional - not available on Python 3.13)
try:
    import FinanceDataReader as fdr
    FDR_AVAILABLE = True
except ImportError:
    fdr = None
    FDR_AVAILABLE = False
    print("âš ï¸ FinanceDataReader ë¯¸ì„¤ì¹˜ (ê²€ìƒ‰/ì‹¤ì‹œê°„ ë°ì´í„° ì œí•œ)")

from datetime import timedelta

# [NICE] Theme Manager for dynamic theme lookup
from kr_market.theme_manager import ThemeManager

# KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™” (ë¹„ë™ê¸° ë¡œë”©)
KRX_STOCKS = pd.DataFrame()

def load_krx_stocks():
    global KRX_STOCKS
    if FDR_AVAILABLE:
        print("â³ KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)...")
        try:
            KRX_STOCKS = fdr.StockListing('KRX')
            if 'Code' in KRX_STOCKS.columns and 'Symbol' not in KRX_STOCKS.columns:
                KRX_STOCKS['Symbol'] = KRX_STOCKS['Code']
            print(f"âœ… KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ: {len(KRX_STOCKS)}ê°œ ì¢…ëª©")
        except Exception as e:
            print(f"âš ï¸ KRX ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨ (ê²€ìƒ‰ ê¸°ëŠ¥ ì œí•œë¨): {e}")

# Start background loading
if FDR_AVAILABLE:
    t = threading.Thread(target=load_krx_stocks)
    t.daemon = True
    t.start()

# [NEW] pykrx for supply data (foreign/institutional trading)
try:
    from pykrx import stock as pykrx_stock
    PYKRX_AVAILABLE = True
    print("âœ… pykrx ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ (ìˆ˜ê¸‰ ë°ì´í„° ì‚¬ìš© ê°€ëŠ¥)")
except ImportError:
    PYKRX_AVAILABLE = False
    print("âš ï¸ pykrx ë¯¸ì„¤ì¹˜ (ìˆ˜ê¸‰ ë°ì´í„° ì œí•œ)")

def get_supply_data(ticker: str, days: int = 5) -> dict:
    """ìµœê·¼ Nì¼ê°„ ì™¸êµ­ì¸/ê¸°ê´€ ìˆœë§¤ìˆ˜ í•©ê³„ ì¡°íšŒ (pykrx ì‚¬ìš©)"""
    if not PYKRX_AVAILABLE:
        return {'foreign_5d': 0, 'inst_5d': 0}
    
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days + 10)  # ì˜ì—…ì¼ ê³ ë ¤ ì—¬ìœ 
        
        # pykrx API í˜¸ì¶œ
        df = pykrx_stock.get_market_trading_value_by_date(
            start_date.strftime('%Y%m%d'),
            end_date.strftime('%Y%m%d'),
            ticker
        )
        
        if df.empty or len(df) < 1:
            return {'foreign_5d': 0, 'inst_5d': 0}
        
        # ìµœê·¼ Nì¼ë§Œ ì‚¬ìš©
        recent = df.tail(days)
        
        # ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ = ì™¸êµ­ì¸ í•©ê³„
        # ê¸°ê´€ ìˆœë§¤ìˆ˜ = ê¸°ê´€ í•©ê³„
        foreign_col = 'ì™¸êµ­ì¸í•©ê³„' if 'ì™¸êµ­ì¸í•©ê³„' in recent.columns else (
            'ì™¸êµ­ì¸' if 'ì™¸êµ­ì¸' in recent.columns else None
        )
        inst_col = 'ê¸°ê´€í•©ê³„' if 'ê¸°ê´€í•©ê³„' in recent.columns else (
            'ê¸°ê´€' if 'ê¸°ê´€' in recent.columns else None
        )
        
        foreign_5d = int(recent[foreign_col].sum()) if foreign_col else 0
        inst_5d = int(recent[inst_col].sum()) if inst_col else 0
        
        return {'foreign_5d': foreign_5d, 'inst_5d': inst_5d}
    except Exception as e:
        print(f"Supply data fetch error ({ticker}): {e}")
        return {'foreign_5d': 0, 'inst_5d': 0}


def search_stock(keyword):
    """ì‹¤ì‹œê°„ ì¢…ëª© ê²€ìƒ‰"""
    if KRX_STOCKS.empty:
        return []
    
    keyword = keyword.upper().strip()
    if not keyword:
        return []
        
    mask = KRX_STOCKS['Symbol'].str.contains(keyword) | KRX_STOCKS['Name'].str.contains(keyword)
    results = KRX_STOCKS[mask].head(10) # ìµœëŒ€ 10ê°œ
    
    output = []
    for _, row in results.iterrows():
        output.append({
            'symbol': row['Symbol'], # Code
            'name': row['Name'],
            'market': row['Market'],
            'sector': row.get('Sector', '')
        })
    return output

def get_real_stock_data(symbol):
    """ì‹¤ì‹œê°„ ì£¼ê°€ ì •ë³´ (FDR ì‚¬ìš©)"""
    if not FDR_AVAILABLE:
        return None  # FinanceDataReader not available
        
    try:
        # ìµœê·¼ 5ì¼ ë°ì´í„° ì¡°íšŒ (ì•ˆì „í•˜ê²Œ)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=7)
        
        df = fdr.DataReader(symbol, start_date, end_date)
        if df.empty:
            return None
            
        last_row = df.iloc[-1]
        prev_row = df.iloc[-2] if len(df) > 1 else last_row
        
        # ê¸°ë³¸ ì •ë³´ í™•ì¸
        name = symbol
        sector = ''
        if not KRX_STOCKS.empty:
            match = KRX_STOCKS[KRX_STOCKS['Symbol'] == symbol]
            if not match.empty:
                name = match.iloc[0]['Name']
                sector = match.iloc[0].get('Sector', '')

        # ë“±ë½ë¥  ê³„ì‚°
        change_rate = 0
        if prev_row['Close'] > 0:
            change_rate = ((last_row['Close'] - prev_row['Close']) / prev_row['Close']) * 100

        return {
            'symbol': symbol,
            'name': name,
            'market': 'KRX',
            'sector': sector,
            'current_price': int(last_row['Close']),
            'change_rate': round(change_rate, 2),
            'volume': int(last_row['Volume']),
            'timestamp': last_row.name.strftime('%Y-%m-%d')
        }
    except Exception as e:
        print(f"Real data fetch error ({symbol}): {e}")
        return None

@app.route('/api/kr/search')
def api_kr_search():
    """í•œêµ­ ì£¼ì‹ ê²€ìƒ‰ API"""
    q = request.args.get('q', '')
    return jsonify(search_stock(q))

# ==================== BACKGROUND PRICE SCHEDULER ====================

def start_kr_price_scheduler():
    """Background thread for live price updates (5min interval, 10s stagger)"""
    def _run_scheduler():
        print("â° KR Price Scheduler started (5min interval, 10s stagger)")
        while True:
            try:
                # 1. Load existing analysis data
                json_path = 'kr_market/data/kr_ai_analysis.json'
                if not os.path.exists(json_path):
                    time.sleep(60)
                    continue

                with open(json_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                signals = data.get('signals', [])
                if not signals:
                    time.sleep(300)
                    continue

                # 2. Iterate and update each ticker
                updated_count = 0
                for signal in signals:
                    ticker = signal.get('ticker')
                    if not ticker:
                        continue

                    try:
                        from kr_market.kr_ai_analyzer import fetch_current_price
                        current_price = fetch_current_price(ticker)
                        
                        if current_price > 0:
                            entry = signal.get('entry_price', 0)
                            signal['current_price'] = current_price
                            if entry > 0:
                                signal['return_pct'] = round(
                                    ((current_price - entry) / entry) * 100, 2
                                )
                            
                            # Save immediately after each update
                            with open(json_path, 'w', encoding='utf-8') as f:
                                json.dump(data, f, ensure_ascii=False, indent=2)
                            
                            print(f"ğŸ”„ Updated price for {signal.get('name')} ({ticker}): {current_price}")
                            updated_count += 1
                        
                    except Exception as e:
                        print(f"Error updating price for {ticker}: {e}")

                    # 3. Stagger delay (10 seconds between tickers)
                    time.sleep(10)

                print(f"âœ… Completed 5-min price update cycle ({updated_count} updated)")
                time.sleep(300)  # Wait 5 minutes before next cycle

            except Exception as e:
                print(f"Scheduler error: {e}")
                time.sleep(60)

    # Start daemon thread
    thread = threading.Thread(target=_run_scheduler, daemon=True)
    thread.start()


# ==================== SECTOR MAPPING SYSTEM ====================

SECTOR_MAP = {
    # Technology
    'AAPL': 'Tech', 'MSFT': 'Tech', 'NVDA': 'Tech', 'AVGO': 'Tech',
    'CRM': 'Tech', 'AMD': 'Tech', 'ADBE': 'Tech', 'CSCO': 'Tech',
    
    # Financials
    'BRK-B': 'Fin', 'JPM': 'Fin', 'V': 'Fin', 'MA': 'Fin',
    'BAC': 'Fin', 'WFC': 'Fin', 'GS': 'Fin', 'MS': 'Fin',
    
    # Healthcare
    'LLY': 'Health', 'UNH': 'Health', 'JNJ': 'Health', 'ABBV': 'Health',
    'MRK': 'Health', 'PFE': 'Health', 'TMO': 'Health', 'ABT': 'Health',
    
    # Energy
    'XOM': 'Energy', 'CVX': 'Energy', 'COP': 'Energy', 'SLB': 'Energy',
    
    # Consumer
    'AMZN': 'Cons', 'TSLA': 'Cons', 'HD': 'Cons', 'MCD': 'Cons',
    'WMT': 'Staple', 'PG': 'Staple', 'COST': 'Staple', 'KO': 'Staple',
    
    # Industrials
    'CAT': 'Indust', 'GE': 'Indust', 'RTX': 'Indust', 'HON': 'Indust',
    
    # Communication
    'META': 'Comm', 'GOOGL': 'Comm', 'NFLX': 'Comm', 'DIS': 'Comm',
    
    # Real Estate
    'PLD': 'REIT', 'AMT': 'REIT', 'EQIX': 'REIT', 'SPG': 'REIT',
}

SECTOR_CACHE_FILE = os.path.join('us_market', 'sector_cache.json')
_sector_cache = {}

def _load_sector_cache():
    """Load sector cache from file"""
    global _sector_cache
    if os.path.exists(SECTOR_CACHE_FILE):
        try:
            with open(SECTOR_CACHE_FILE, 'r') as f:
                _sector_cache = json.load(f)
        except:
            _sector_cache = {}

def _save_sector_cache(cache):
    """Save sector cache to file"""
    os.makedirs(os.path.dirname(SECTOR_CACHE_FILE), exist_ok=True)
    with open(SECTOR_CACHE_FILE, 'w') as f:
        json.dump(cache, f, indent=2)

def get_sector(ticker: str) -> str:
    """Get sector for a ticker, auto-fetch from yfinance if not in SECTOR_MAP"""
    global _sector_cache
    
    # Check static map first
    if ticker in SECTOR_MAP:
        return SECTOR_MAP[ticker]
    
    # Check persistent cache
    if ticker in _sector_cache:
        return _sector_cache[ticker]
    
    # Fetch from yfinance and cache
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        sector = info.get('sector', '')
        
        # Map to short code
        sector_short_map = {
            'Technology': 'Tech',
            'Healthcare': 'Health',
            'Financials': 'Fin',
            'Consumer Discretionary': 'Cons',
            'Consumer Staples': 'Staple',
            'Energy': 'Energy',
            'Industrials': 'Indust',
            'Materials': 'Mater',
            'Utilities': 'Util',
            'Real Estate': 'REIT',
            'Communication Services': 'Comm',
        }
        
        short_sector = sector_short_map.get(sector, sector[:5] if sector else '-')
        
        # Persist to cache
        _sector_cache[ticker] = short_sector
        _save_sector_cache(_sector_cache)
        
        return short_sector
    except Exception as e:
        _sector_cache[ticker] = '-'
        return '-'


# ==================== PAGE ROUTES ====================

@app.route('/')
def home():
    """Landing page"""
    return render_template('index.html')


@app.route('/app')
@app.route('/dashboard')
def dashboard():
    """Main dashboard with all market views"""
    return render_template('dashboard.html')


@app.route('/dividend')
def dividend_page():
    """Dividend portfolio optimization page"""
    return render_template('dashboard.html')


# ==================== KR MARKET API ROUTES ====================

@app.route('/api/kr/market-status')
def kr_market_status():
    """Check if KR market is open"""
    try:
        now = datetime.now()
        is_weekday = now.weekday() < 5
        is_trading_hours = 9 <= now.hour < 16
        is_open = is_weekday and is_trading_hours
        
        return jsonify({
            'status': 'success',
            'is_open': is_open,
            'message': 'ì¥ ì¤‘' if is_open else 'ì¥ ë§ˆê°'
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/kr/signals')
def get_kr_signals():
    """ì˜¤ëŠ˜ì˜ VCP + ì™¸ì¸ë§¤ì§‘ ì‹œê·¸ë„ (Top 20 ìˆœìœ„)"""
    try:
        signals_path = 'kr_market/data/signals_log.csv'
        
        if not os.path.exists(signals_path):
            return jsonify({
                'signals': [],
                'count': 0,
                'message': 'ì‹œê·¸ë„ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìŠ¤ìº”ì„ ì‹¤í–‰í•˜ì„¸ìš”.'
            })
        
        df = pd.read_csv(signals_path, encoding='utf-8-sig')
        df['ticker'] = df['ticker'].astype(str).str.zfill(6)
        
        # ì¢…ëª©ëª… ë° ì‹œì¥ ì •ë³´ ë¡œë“œ
        stock_names = {}
        stock_markets = {}
        stocks_file = 'kr_market/data/stock_list.csv'
        if os.path.exists(stocks_file):
            stocks_df = pd.read_csv(stocks_file, encoding='utf-8-sig', dtype={'ticker': str})
            stocks_df['ticker'] = stocks_df['ticker'].astype(str).str.zfill(6)
            stock_names = dict(zip(stocks_df['ticker'], stocks_df['name']))
            stock_markets = dict(zip(stocks_df['ticker'], stocks_df['market']))
        
        # ìµœì‹  ì‹œê·¸ë„ (OPEN ìƒíƒœ)
        if 'status' not in df.columns:
            df['status'] = 'OPEN'
        open_signals = df[df['status'] == 'OPEN'].copy()
        today = datetime.now().strftime('%Y-%m-%d')
        
        signals = []
        for _, row in open_signals.iterrows():
            score = float(row['score']) if pd.notna(row['score']) else 0
            contraction = float(row['contraction_ratio']) if pd.notna(row['contraction_ratio']) else 1
            foreign_5d = int(row['foreign_5d']) if pd.notna(row['foreign_5d']) else 0
            inst_5d = int(row['inst_5d']) if pd.notna(row['inst_5d']) else 0
            signal_date = row['signal_date']
            
            # ì œì™¸ ì¡°ê±´
            # [Sanitization] Ignore future dates
            if signal_date > today:
                continue
                
            if contraction > 0.8:  # ìˆ˜ì¶• ë¯¸ì™„ë£Œ
                continue
            if foreign_5d < 0 and inst_5d < 0:  # ìˆ˜ê¸‰ ëª¨ë‘ ì´íƒˆ
                continue
            if score < 50:  # ê¸°ë³¸ ì ìˆ˜ ë¯¸ë‹¬
                continue
            
            # Final Score ê³„ì‚°
            contraction_score = (1 - contraction) * 100
            supply_score = min((foreign_5d + inst_5d) / 100000, 30)
            today_bonus = 10 if signal_date == today else 0
            
            final_score = (score * 0.4) + (contraction_score * 0.3) + (supply_score * 0.2 * 10) + today_bonus
            
            # Compute nice_layers for Radar Chart (approximation based on available data)
            L1_technical = min(int(score), 100)  # VCP score as technical
            L2_supply = min(int((1 - contraction) * 30), 30)  # Contraction -> supply
            L3_sentiment = 50  # Default neutral
            L4_macro = 35  # Default
            L5_institutional = min(int((foreign_5d + inst_5d) / 1e8), 35)  # Normalize flow
            nice_total = L1_technical + L2_supply + L3_sentiment + L4_macro + L5_institutional
            
            signals.append({
                'ticker': row['ticker'],
                'name': stock_names.get(row['ticker'], ''),
                'market': stock_markets.get(row['ticker'], ''),
                'theme': ThemeManager.get_theme(str(row['ticker']).zfill(6)) or '',  # [NICE] Dynamic theme lookup
                'signal_date': signal_date,
                'foreign_5d': foreign_5d,
                'inst_5d': inst_5d,
                'score': round(score, 1),
                'contraction_ratio': round(contraction, 2),
                'entry_price': round(row['entry_price'], 0) if pd.notna(row['entry_price']) else 0,
                'status': row['status'],
                'final_score': round(final_score, 1),
                # NICE Layers for Radar Chart
                'nice_layers': {
                    'L1_technical': L1_technical,
                    'L2_supply': L2_supply,
                    'L3_sentiment': L3_sentiment,
                    'L4_macro': L4_macro,
                    'L5_institutional': L5_institutional,
                    'total': nice_total,
                    'max_total': 300
                },
                # NICE Plan Fields
                'stop_loss': row.get('stop_loss', 0),
                'tp1': row.get('tp1', 0),
                'tp2': row.get('tp2', 0),
                'time_stop': row.get('time_stop', ''),
                'min_turnover': row.get('min_turnover', 0)
            })
        
        # ========== í…Œë§ˆ ì¢…ëª© ìë™ ì¶”ê°€ (í…Œë§ˆ íƒ­ì´ ë¹„ì–´ ìˆì§€ ì•Šë„ë¡) ==========
        existing_tickers = {s['ticker'] for s in signals}
        theme_tickers = ThemeManager.get_all_target_tickers()
        
        for t_ticker in theme_tickers:
            t_ticker = str(t_ticker).zfill(6)
            if t_ticker in existing_tickers:
                continue  # ì´ë¯¸ ì‹œê·¸ë„ì— ìˆìŒ
            
            theme = ThemeManager.get_theme(t_ticker)
            if not theme:
                continue
            
            # ê¸°ë³¸ ì‹œê·¸ë„ ìƒì„± (VCP ìŠ¤ìº” ì—†ì´ í…Œë§ˆ ì¢…ëª©ìœ¼ë¡œ ì¶”ê°€)
            t_name = stock_names.get(t_ticker, t_ticker)
            t_market = stock_markets.get(t_ticker, 'KOSPI')
            
            # í˜„ì¬ê°€ ì¡°íšŒ
            try:
                cp = get_real_stock_data(t_ticker)
                current_price = cp.get('current_price', 0) if cp else 0
            except:
                current_price = 0
            
            if current_price <= 0:
                continue
            
            signals.append({
                'ticker': t_ticker,
                'name': t_name,
                'market': t_market,
                'theme': theme,
                'signal_date': today,
                'foreign_5d': 0,
                'inst_5d': 0,
                'score': 65,  # í…Œë§ˆ ê¸°ë³¸ ì ìˆ˜
                'contraction_ratio': 0.5,
                'entry_price': current_price,
                'current_price': current_price,
                'return_pct': 0,
                'status': 'THEME',
                'final_score': 55,  # í…Œë§ˆ ê¸°ë³¸ ì ìˆ˜
                # NICE Layers for Radar Chart (Theme default)
                'nice_layers': {
                    'L1_technical': 65,
                    'L2_supply': 15,
                    'L3_sentiment': 50,
                    'L4_macro': 35,
                    'L5_institutional': 10,
                    'total': 175,
                    'max_total': 300
                },
                'stop_loss': int(current_price * 0.93),
                'tp1': int(current_price * 1.10),
                'tp2': int(current_price * 1.20),
                'time_stop': '',
                'min_turnover': 0
            })
        
        # final_score ê¸°ì¤€ ì •ë ¬ í›„ Top 20
        signals_sorted = sorted(signals, key=lambda x: x['final_score'], reverse=True)[:20]
        
        # Top 20ì— ëŒ€í•´ í˜„ì¬ê°€ ì¡°íšŒ ë° ìˆ˜ìµë¥  ê³„ì‚°
        if signals_sorted:
            # í‹°ì»¤ ë§µ ë¡œë“œ (Yahoo Financeìš©)
            ticker_map = {}
            ticker_map_file = 'kr_market/ticker_to_yahoo_map.csv'
            if os.path.exists(ticker_map_file):
                try:
                    tm_df = pd.read_csv(ticker_map_file, dtype=str)
                    ticker_map = dict(zip(tm_df['ticker'].str.zfill(6), tm_df['yahoo_ticker']))
                except:
                    pass
            
            # Yahoo í‹°ì»¤ ë³€í™˜
            tickers = [s['ticker'] for s in signals_sorted]
            yahoo_tickers = [ticker_map.get(t, f"{t}.KS") for t in tickers]
            
            # í˜„ì¬ê°€ ì¡°íšŒ
            current_prices = {}
            try:
                data = yf.download(yahoo_tickers, period='1d', progress=False)
                if not data.empty and 'Close' in data.columns:
                    closes = data['Close']
                    if isinstance(closes, pd.Series):
                        closes = closes.to_frame()
                        closes.columns = yahoo_tickers
                    for orig, yf_t in zip(tickers, yahoo_tickers):
                        if yf_t in closes.columns:
                            val = closes[yf_t].iloc[-1]
                            if not pd.isna(val):
                                current_prices[orig] = float(val)
            except Exception as e:
                print(f"Price fetch error: {e}")
            
            # í˜„ì¬ê°€ ë° ìˆ˜ìµë¥  ì¶”ê°€
            for sig in signals_sorted:
                entry = sig['entry_price']
                curr = current_prices.get(sig['ticker'], entry)
                sig['current_price'] = round(curr, 0)
                if entry > 0 and curr > 0:
                    sig['return_pct'] = round(((curr - entry) / entry) * 100, 2)
                else:
                    sig['return_pct'] = 0
        
        return jsonify({
            'signals': signals_sorted,
            'count': len(signals_sorted),
            'total_filtered': len(signals),
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/history/<ticker>')
def get_kr_history(ticker):
    """Get price history for a ticker (Direct list for Lightweight Charts)"""
    try:
        # Fetch chart data using FDR or yfinance fallback
        symbol = ticker
        
        # ê¸°ê°„ ì„¤ì •
        period_days = 365
        period_arg = request.args.get('period', '1y')
        
        if period_arg == '1mo': period_days = 30
        elif period_arg == '3mo': period_days = 90
        elif period_arg == '6mo': period_days = 180
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)
        
        df = pd.DataFrame()
        
        # Try FinanceDataReader first
        if FDR_AVAILABLE:
            try:
                df = fdr.DataReader(symbol, start_date, end_date)
            except Exception as fdr_err:
                print(f"FDR fetch failed for {ticker}: {fdr_err}")
        
        # Fallback to yfinance if FDR failed or unavailable
        if df.empty:
            try:
                yahoo_ticker = f"{symbol}.KS"
                df = yf.download(yahoo_ticker, start=start_date, end=end_date, progress=False)
                if df.empty:
                    yahoo_ticker = f"{symbol}.KQ"  # Try KOSDAQ
                    df = yf.download(yahoo_ticker, start=start_date, end=end_date, progress=False)
            except Exception as yf_err:
                print(f"YFinance fetch failed for {ticker}: {yf_err}")
        
        if df.empty:
            return jsonify([]), 200 # Return empty list instead of 404 for safer frontend handling
        
        chart_data = []
        today_str = datetime.now().strftime('%Y-%m-%d')
        
        for date, row in df.iterrows():
            date_str = date.strftime('%Y-%m-%d')
            # [Sanitization] Ignore future dates (test data artifacts)
            if date_str > today_str:
                continue
                
            chart_data.append({
                'date': date_str,
                'open': int(row['Open']),
                'high': int(row['High']),
                'low': int(row['Low']),
                'close': int(row['Close']),
                'volume': int(row['Volume'])
            })
        
        return jsonify(chart_data)
        
    except Exception as e:
        print(f"History fetch error for {ticker}: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/ai-analysis')
def kr_ai_analysis():
    """
    Get AI recommendations (Synced with Real-time Signals + Cached AI Text)
    This ensures the Left Dashboard matches the Right Dashboard's ranking.
    """
    try:
        # 1. Fetch Fresh Real-time Signals (Reuse logic from Signals API)
        # This returns the current Top 20 based on Real-time Price & Total Score
        fresh_response = get_kr_signals()
        
        # Handle Flask Response object
        if hasattr(fresh_response, 'get_json'):
            fresh_data = fresh_response.get_json()
        elif hasattr(fresh_response, 'data'):
            fresh_data = json.loads(fresh_response.data)
        else:
            fresh_data = {}
            
        fresh_signals = fresh_data.get('signals', [])
        
        # 2. Load Cached AI Text (to save API costs and latency)
        cached_ai_texts = {}
        cached_market_analysis = {}
        KR_AI_ANALYSIS_FILE = 'kr_market/data/kr_ai_analysis.json'
        
        if os.path.exists(KR_AI_ANALYSIS_FILE):
            try:
                with open(KR_AI_ANALYSIS_FILE, 'r', encoding='utf-8') as f:
                    cached_full = json.load(f)
                    
                    # Extract Market Analysis
                    cached_market_analysis = cached_full.get('market_analysis', {})
                    
                    # Extract Stock Analysis (Index by Ticker)
                    if 'signals' in cached_full:
                        for s in cached_full['signals']:
                            ticker = str(s.get('ticker')).zfill(6)
                            cached_ai_texts[ticker] = {
                                'gpt': s.get('gpt_recommendation'),
                                'gemini': s.get('gemini_recommendation')
                            }
            except Exception as e:
                print(f"Cache load error: {e}")
        
        # 3. Merge AI Text into Fresh Signals
        final_signals = []
        for sig in fresh_signals:
            ticker = str(sig.get('ticker')).zfill(6)
            
            # Use cached text if available, otherwise default
            ai_text = cached_ai_texts.get(ticker, {})
            
            sig['gpt_recommendation'] = ai_text.get('gpt', {
                'action': 'HOLD', 
                'reason': 'ì‹ ê·œ ì§„ì… ì¢…ëª© (AI ë¶„ì„ ëŒ€ê¸° ì¤‘)', 
                'confidence': 50
            })
            sig['gemini_recommendation'] = ai_text.get('gemini', {
                'action': 'HOLD', 
                'reason': 'ì‹ ê·œ ì§„ì… ì¢…ëª© (AI ë¶„ì„ ëŒ€ê¸° ì¤‘)', 
                'confidence': 50
            })
            
            final_signals.append(sig)
            
        # 4. Construct Final Result
        # Left screen expects 'signals' and 'market_analysis'
        result = {
            'signals': final_signals, # Already sorted by get_kr_signals (Total Score)
            'market_analysis': cached_market_analysis,
            'signal_date': datetime.now().strftime('%Y-%m-%d'), # Live date
            'count': len(final_signals),
            'note': 'Real-time data synced with Signals API'
        }
        
        return jsonify(result)

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/analyze-stock', methods=['POST'])
def api_kr_analyze_stock():
    """Real-time On-Demand AI Analysis"""
    try:
        data = request.json
        ticker = data.get('ticker')
        if not ticker:
            return jsonify({'error': 'Ticker is required'}), 400
            
        print(f"ğŸš€ On-Demand Analysis Triggered for {ticker}")
        
        from kr_market.kr_ai_analyzer import analyze_single_stock_realtime
        
        # [Preserve Data Logic] Load existing cached data to keep foreign/inst scores
        cached_signal = None
        try:
            cache_file = 'kr_market/data/kr_ai_analysis.json'
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    for s in cached_data.get('signals', []):
                        if s.get('ticker') == ticker.zfill(6):
                            cached_signal = s
                            break
        except: pass

        result = analyze_single_stock_realtime(ticker, cached_signal)
        
        # Save or Log if needed? For now just return
        return jsonify(result)
        
    except Exception as e:
        print(f"On-Demand Analysis Error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/ai-summary/<ticker>')
def kr_ai_summary(ticker):
    """Get individual AI summary for a stock"""
    try:
        # Load AI analysis
        cache_file = 'kr_market/data/kr_ai_analysis.json'
        if not os.path.exists(cache_file):
            return jsonify({'error': 'No AI analysis available'}), 404
        
        with open(cache_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Find ticker in signals
        signals = data.get('signals', [])
        for signal in signals:
            if signal.get('ticker') == ticker.zfill(6):
                return jsonify(signal)
        
        return jsonify({'error': 'Ticker not found in analysis'}), 404
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/ai-history-dates')
def get_kr_ai_history_dates():
    """Get list of available KR AI analysis history dates"""
    try:
        history_dir = 'kr_market/data/history'
        
        if not os.path.exists(history_dir):
            return jsonify({'dates': []})
        
        dates = []
        for filename in os.listdir(history_dir):
            if filename.startswith('kr_ai_analysis_') and filename.endswith('.json'):
                # Extract date from filename
                date = filename.replace('kr_ai_analysis_', '').replace('.json', '')
                dates.append(date)
        
        # Sort descending (newest first)
        dates.sort(reverse=True)
        
        return jsonify({
            'dates': dates,
            'count': len(dates)
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/ai-history/<date>')
def get_kr_ai_history(date):
    """Get KR AI analysis for a specific date"""
    try:
        history_file = f'kr_market/data/history/kr_ai_analysis_{date}.json'
        
        if not os.path.exists(history_file):
            return jsonify({'error': f'No analysis found for {date}'}), 404
        
        with open(history_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return jsonify(data)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/cumulative-return')
def get_kr_cumulative_return():
    """Calculate cumulative return for KR signals portfolio"""
    try:
        signals_path = 'kr_market/data/signals_log.csv'
        
        if not os.path.exists(signals_path):
            return jsonify({'error': 'No signals file'}), 404
        
        df = pd.read_csv(signals_path, encoding='utf-8-sig')
        df['ticker'] = df['ticker'].astype(str).str.zfill(6)
        
        # Get OPEN signals
        open_signals = df[df['status'] == 'OPEN']
        
        # Calculate returns for each signal
        returns = []
        for _, row in open_signals.iterrows():
            entry = row['entry_price']
            ticker = row['ticker']
            
            # Fetch current price
            try:
                from kr_market.kr_ai_analyzer import fetch_current_price
                current = fetch_current_price(ticker)
                if current > 0 and entry > 0:
                    ret = ((current - entry) / entry) * 100
                    returns.append({
                        'ticker': ticker,
                        'return_pct': round(ret, 2)
                    })
            except:
                pass
        
        # Calculate portfolio metrics
        if returns:
            avg_return = sum(r['return_pct'] for r in returns) / len(returns)
            winners = len([r for r in returns if r['return_pct'] > 0])
            losers = len([r for r in returns if r['return_pct'] <= 0])
            win_rate = (winners / len(returns)) * 100 if returns else 0
        else:
            avg_return = 0
            win_rate = 0
            winners = 0
            losers = 0
        
        return jsonify({
            'cumulative_return': round(avg_return, 2),
            'win_rate': round(win_rate, 1),
            'winners': winners,
            'losers': losers,
            'total_positions': len(returns),
            'positions': returns
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/performance')
def kr_performance():
    """Get signal performance metrics"""
    try:
        from kr_market import signal_tracker
        tracker = signal_tracker.SignalTracker()
        report = tracker.get_performance_report()
        
        return jsonify({'status': 'success', 'data': report})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/kr/market-gate')
def get_kr_market_gate():
    """Get KR market condition gate status"""
    try:
        from kr_market.market_gate import get_market_status
        
        status = get_market_status()
        
        return jsonify({
            'status': status.get('status', 'UNKNOWN'),
            'kospi': status.get('kospi', {}),
            'kosdaq': status.get('kosdaq', {}),
            'usd_krw': status.get('usd_krw', 0),
            'foreign_net': status.get('foreign_net', 0),
            'gate_score': status.get('gate_score', 0),
            'recommendation': status.get('recommendation', ''),
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/vcp-scan')
def kr_vcp_scan():
    """Run VCP scanner"""
    try:
        from kr_market import signal_tracker
        tracker = signal_tracker.SignalTracker()
        signals = tracker.scan_today_signals()
        
        return jsonify({
            'status': 'success',
            'data': signals.to_dict('records') if not signals.empty else [],
            'count': len(signals)
        })
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'status': 'error', 'message': str(e)}), 500


# ==================== ì¢…ê°€ë² íŒ… V2 API (ENGINE MODULE) ====================

@app.route('/api/kr/jongga-v2')
def api_jongga_v2():
    """ì¢…ê°€ë² íŒ… V2 ì‹œê·¸ë„ ì¡°íšŒ (ë°ì´í„° íŒŒì¼ ê¸°ë°˜)"""
    try:
        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        data_file = 'data/jongga_v2_latest.json'
        
        if not os.path.exists(data_file):
            return jsonify({
                'signals': [],
                'count': 0,
                'message': 'ì‹œê·¸ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. /api/kr/jongga-v2/run ì„ ì‹¤í–‰í•˜ì„¸ìš”.'
            })
        
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return jsonify(data)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/jongga-v2/run', methods=['POST'])
def api_jongga_v2_run():
    """ì¢…ê°€ë² íŒ… V2 ìŠ¤í¬ë¦¬ë„ˆ ì‹¤í–‰"""
    try:
        import asyncio
        from engine.generator import run_screener
        
        # ìë³¸ê¸ˆ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ 5ì²œë§Œì›)
        data = request.json or {}
        capital = data.get('capital', 50_000_000)
        markets = data.get('markets', ['KOSPI', 'KOSDAQ'])
        
        # ë¹„ë™ê¸° ì‹¤í–‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        result = loop.run_until_complete(run_screener(
            capital=capital,
            markets=markets,
            save_result=True
        ))
        
        loop.close()
        
        return jsonify({
            'status': 'success',
            'signals_count': len(result.signals),
            'processing_time_ms': result.processing_time_ms,
            'updated_at': result.updated_at
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/jongga-v2/history')
def api_jongga_v2_history():
    """ì¢…ê°€ë² íŒ… V2 íˆìŠ¤í† ë¦¬ ë‚ ì§œ ëª©ë¡"""
    try:
        import glob
        
        history_files = glob.glob('data/jongga_v2_results_*.json')
        dates = []
        
        for f in history_files:
            # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ: jongga_v2_results_20260202.json
            basename = os.path.basename(f)
            date_part = basename.replace('jongga_v2_results_', '').replace('.json', '')
            if len(date_part) == 8:
                formatted = f"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]}"
                dates.append(formatted)
        
        dates.sort(reverse=True)
        
        return jsonify({
            'dates': dates,
            'count': len(dates)
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/jongga-v2/history/<date>')
def api_jongga_v2_history_date(date):
    """íŠ¹ì • ë‚ ì§œì˜ ì¢…ê°€ë² íŒ… V2 ì‹œê·¸ë„ ì¡°íšŒ"""
    try:
        date_str = date.replace('-', '')
        data_file = f'data/jongga_v2_results_{date_str}.json'
        
        if not os.path.exists(data_file):
            return jsonify({'error': f'No data for {date}'}), 404
        
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return jsonify(data)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/jongga-v2/status')
def api_jongga_v2_status():
    """ì¢…ê°€ë² íŒ… V2 ë°ì´í„° ìƒíƒœ í™•ì¸"""
    try:
        data_file = 'data/jongga_v2_latest.json'
        
        if not os.path.exists(data_file):
            return jsonify({
                'status': 'NO_DATA',
                'last_updated': None,
                'signals_count': 0
            })
        
        # íŒŒì¼ ìˆ˜ì • ì‹œê°„
        mod_time = datetime.fromtimestamp(os.path.getmtime(data_file))
        
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        signals = data.get('signals', [])
        
        # ë“±ê¸‰ë³„ ì¹´ìš´íŠ¸
        grade_counts = {}
        for s in signals:
            grade = s.get('grade', 'C')
            grade_counts[grade] = grade_counts.get(grade, 0) + 1
        
        return jsonify({
            'status': 'OK',
            'last_updated': mod_time.isoformat(),
            'signals_count': len(signals),
            'by_grade': grade_counts,
            'date': data.get('date', ''),
            'processing_time_ms': data.get('processing_time_ms', 0)
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500



# ==================== MACRO ECONOMIC INDICATORS API ====================

@app.route('/api/kr/macro-indicators')
def get_macro_indicators():
    """í†µí•© ë§¤í¬ë¡œ ê²½ì œ ì§€í‘œ ì¡°íšŒ"""
    try:
        from kr_market.macro_indicators import get_all_macro_indicators
        return jsonify(get_all_macro_indicators())
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/exchange-rate')
def get_exchange_rate():
    """ì‹¤ì‹œê°„ USD/KRW í™˜ìœ¨"""
    try:
        from kr_market.macro_indicators import get_usd_krw_rate
        return jsonify(get_usd_krw_rate())
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/interest-spread')
def get_interest_spread():
    """í•œë¯¸ ê¸ˆë¦¬ì°¨"""
    try:
        from kr_market.macro_indicators import get_interest_rate_spread
        return jsonify(get_interest_rate_spread())
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/fx-reserves')
def get_fx_reserves():
    """ì™¸í™˜ë³´ìœ ì•¡"""
    try:
        from kr_market.macro_indicators import get_fx_reserves
        return jsonify(get_fx_reserves())
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/hot-themes')
def api_kr_hot_themes():
    """Get AI analysis for hot themes (Defense, Chips, AI Power)"""
    try:
        cache_file = 'kr_market/data/cache/theme_analysis.json'
        
        # Check cache (VALID FOR 6 HOURS)
        if os.path.exists(cache_file):
            mod_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
            if datetime.now() - mod_time < timedelta(hours=6):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return jsonify(json.load(f))

        # Generate new analysis
        from kr_market.kr_ai_analyzer import analyze_market_theme
        
        targets = [
            {'name': 'Defense (ë°©ì‚°)', 'query': 'êµ­ë‚´ ë°©ì‚°'},
            {'name': 'Semiconductor (ë°˜ë„ì²´)', 'query': 'êµ­ë‚´ ë°˜ë„ì²´'},
            {'name': 'AI / Power (AIì „ë ¥)', 'query': 'êµ­ë‚´ ì „ë ¥ì„¤ë¹„ ë° ì „ì„ '}
        ]
        
        results = []
        for t in targets:
            analysis = analyze_market_theme(t['query'])
            results.append({
                'name': t['name'],
                'analysis': analysis.get('analysis', 'ë¶„ì„ ë¶ˆê°€'),
                'outlook': analysis.get('outlook', 'Neutral')
            })
            
        final_data = {
            'themes': results,
            'updated_at': datetime.now().isoformat()
        }
        
        # Save cache
        os.makedirs(os.path.dirname(cache_file), exist_ok=True)
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=2)
            
        return jsonify(final_data)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/sector-performance')
def get_sector_perf():
    """ì„¹í„°ë³„ ì„±ê³¼"""
    try:
        from kr_market.macro_indicators import get_sector_performance
        return jsonify(get_sector_performance())
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/crisis-indicators')
def get_crisis_indicators():
    """ìœ„ê¸° ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë‹ˆí„°"""
    try:
        from kr_market.macro_indicators import get_crisis_indicators
        return jsonify(get_crisis_indicators())
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/strategy-comparison')
def strategy_comparison():
    """ì „ëµ ëª¨ë“œë³„ ì„±ê³¼ ë¹„êµ for A/B testing"""
    try:
        from kr_market.performance_analyzer import PerformanceAnalyzer
        from kr_market.signal_tracker import StrategyMode
        
        analyzer = PerformanceAnalyzer()
        modes = [mode.value for mode in StrategyMode]
        comparison = analyzer.get_strategy_comparison(modes)
        
        return jsonify({
            'status': 'success',
            'comparison': comparison,
            'available_modes': modes
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/ai-performance')
def ai_performance():
    """AI ì¶”ì²œ íš¨ê³¼ì„± ë¶„ì„"""
    try:
        from kr_market.ai_performance_tracker import AIPerformanceTracker
        
        tracker = AIPerformanceTracker()
        report = tracker.generate_ai_effectiveness_report()
        
        return jsonify({
            'status': 'success',
            'report': report
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/performance-report')
def performance_report():
    """ì¢…í•© ì„±ê³¼ ë¦¬í¬íŠ¸"""
    try:
        from kr_market.performance_analyzer import PerformanceAnalyzer
        
        mode = request.args.get('mode', None)
        analyzer = PerformanceAnalyzer()
        report = analyzer.generate_comprehensive_report(mode)
        
        return jsonify({
            'status': 'success',
            'report': report
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== GENIUS QUESTION & NICE LAYER API ====================

@app.route('/api/kr/genius-analysis/<ticker>')
def genius_analysis(ticker):
    """ì²œì¬ë“¤ì˜ ì§ˆë¬¸ë²• (5Why + SCAMPER) ë¶„ì„ API"""
    try:
        from kr_market.advanced_analyzer import GeniusQuestionMethod
        
        # ì¢…ëª© ë°ì´í„° ë¡œë“œ
        ticker = ticker.zfill(6)
        stock_data = get_real_stock_data(ticker)
        if not stock_data:
            stock_data = {'name': ticker, 'current_price': 0}
        
        # 5Why ë¶„ì„
        five_why = GeniusQuestionMethod.five_why_analysis(
            ticker, 'íˆ¬ì ì í•©ì„± ë¶„ì„', stock_data
        )
        
        # SCAMPER ë¶„ì„
        scamper = GeniusQuestionMethod.scamper_analysis(ticker, stock_data)
        
        return jsonify({
            'status': 'success',
            'ticker': ticker,
            'five_why': five_why,
            'scamper': scamper
        })
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/kr/nice-layer/<ticker>')
def nice_layer_analysis(ticker):
    """NICE 5-Layer ë¶„ì„ API - í•œêµ­ì£¼ì‹ ë§ì¶¤í˜•"""
    try:
        ticker = ticker.zfill(6)
        stock_data = get_real_stock_data(ticker)
        
        # ê¸°ë³¸ê°’
        l1_tech = 50
        l2_supply = 15
        l3_sentiment = 50
        l4_macro = 20
        l5_inst = 15
        
        if stock_data:
            price = stock_data.get('current_price', 0)
            change = stock_data.get('change_pct', 0)
            
            # L1: ê¸°ìˆ ì  ë¶„ì„ (ê°€ê²© ë³€ë™ ê¸°ë°˜)
            if change > 3:
                l1_tech = 85
            elif change > 1:
                l1_tech = 70
            elif change > -1:
                l1_tech = 55
            else:
                l1_tech = 35
            
            # í…Œë§ˆ ê¸°ë°˜ ì ìˆ˜ ë³´ë„ˆìŠ¤
            from kr_market.theme_manager import ThemeManager
            theme = ThemeManager.get_theme(ticker)
            if theme in ['ë°˜ë„ì²´', 'AIì¸í”„ë¼']:
                l1_tech = min(100, l1_tech + 10)
                l2_supply = min(30, l2_supply + 5)
            elif theme in ['ì¡°ì„ ', 'ë°©ì‚°']:
                l4_macro = min(40, l4_macro + 8)
                l5_inst = min(30, l5_inst + 5)
        
        total_score = l1_tech + l2_supply + l3_sentiment + l4_macro + l5_inst
        
        return jsonify({
            'status': 'success',
            'ticker': ticker,
            'layers': {
                'L1_technical': l1_tech,
                'L2_supply': l2_supply,
                'L3_sentiment': l3_sentiment,
                'L4_macro': l4_macro,
                'L5_institutional': l5_inst
            },
            'total_score': total_score,
            'max_total': 300
        })
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


# ==================== ERROR HANDLERS ====================

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'status': 'error',
        'message': 'Internal server error',
        'details': str(error)
    }), 500


@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'status': 'error',
        'message': 'Endpoint not found'
    }), 404


# ==================== SERVER STARTUP ====================

if __name__ == '__main__':
    # Load sector cache
    _load_sector_cache()
    
    # Start background scheduler
    start_kr_price_scheduler()
    
    # Start Flask server
    print("ğŸš€ Flask Server Starting on port 5001...")
    app.run(debug=True, host='127.0.0.1', port=5001)
